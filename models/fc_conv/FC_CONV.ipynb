{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armughan/anaconda3/envs/py3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "import keras.activations as A\n",
    "import keras.optimizers as O\n",
    "import keras.losses as Loss\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as KB\n",
    "from keras.callbacks import Callback\n",
    "import time\n",
    "from fc_conv import FC_CONV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOTDIR=os.path.abspath(\"../../\")\n",
    "sys.path.append(ROOTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing.Preprocessor import preprocessor\n",
    "from data_utils.keras_generator import Generator\n",
    "from utils.losses import weighted_cross_entropy_loss,f1_score_metric\n",
    "from utils.callbacks import get_tensorboard_callback,get_checkpoint_call_back\n",
    "from utils.tools import construct_model_from_csv\n",
    "from models.BaseModel import Base_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_dir=os.path.join(ROOTDIR,\"Preprocessing\")\n",
    "data_dir=os.path.join(ROOTDIR,\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armughan/anaconda3/envs/py3.6/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "files=os.listdir(data_dir)\n",
    "array=pd.read_hdf(os.path.join(data_dir,files[0]))\n",
    "\n",
    "P=preprocessor(label_encoder_dir)\n",
    "array=P.process_batch(array)\n",
    "action_col=array.columns=='action'\n",
    "\n",
    "p_config={'labels':6,\n",
    "        'weightage':[1,1,1,1,1,1],\n",
    "        'data_directory':data_dir,\n",
    "        'file_batch_size':1,\n",
    "        'format_':'h5',\n",
    "        'ex_batch_size':50,\n",
    "        'file_examples':5000,\n",
    "        'max_queue_size':4,\n",
    "        'Preprocessor':P,\n",
    "        'static_weightage':False,\n",
    "         'action_col':action_col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_CONV_Generator(Generator):\n",
    "    def __init__(self,config):\n",
    "        super().__init__(config)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x,targets=super().__getitem__(idx)\n",
    "        ob_net=(x[:,2:467]).reshape(-1,155,3,1)\n",
    "        num_cols=x.shape[1]\n",
    "#         print (num_cols)\n",
    "        scalar_features_col_mask=np.arange(num_cols)\n",
    "        scalar_features_col_mask=(scalar_features_col_mask<2 ) |(scalar_features_col_mask>=467 )\n",
    "        scalar_features=x[:,scalar_features_col_mask]\n",
    "        \n",
    "        return [ob_net,scalar_features],targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=FC_CONV_Generator(config=p_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armughan/anaconda3/envs/py3.6/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "p1 = Process(target=G.generate)\n",
    "p1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armughan/Desktop/side projects/aai/cloned/development/new/internship.ai/models/fc_conv/fc_conv.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  self.Model=Model(inputs=[conv_input,scalar_features],output=logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 155, 3, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 155, 3, 64)   640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 155, 3, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           512         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 155, 3, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 155, 3, 128)  73856       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 155, 3, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 155, 3, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 59520)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 59648)        0           flatten_1[0][0]                  \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          30540288    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            3078        activation_5[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 30,630,278\n",
      "Trainable params: 30,628,486\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=[(155,3,1),(7,)]\n",
    "num_outputs=p_config['labels']\n",
    "optimizer=O.Adam(lr=0.0001)\n",
    "design_config_files=[\"conv_net.csv\",\"fc_net.csv\",\"merged_net.csv\"]\n",
    "model=FC_CONV(input_shape=input_shape,num_outputs=num_outputs,\n",
    "        optimizer=optimizer,arch_config_files=design_config_files)\n",
    "model.construct_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 623/1000 [=================>............] - ETA: 7:49 - loss: 0.2349 - acc: 0.8888 - f1_calc: 0.4394"
     ]
    }
   ],
   "source": [
    "model.train_generator(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
