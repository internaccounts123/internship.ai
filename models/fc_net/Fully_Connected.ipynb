{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from generic_model import Model\n",
    "from keras import optimizers\n",
    "import keras.backend as KB\n",
    "import keras.losses as Loss\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOTDIR=os.path.abspath(\"../\")\n",
    "label_encoder_dir=os.path.join(ROOTDIR,\"Preprocessing\")\n",
    "data_dir=os.path.join(ROOTDIR,\"Data\")\n",
    "sys.path.append(ROOTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Preprocessing.Preprocessor import preprocessor\n",
    "from data_utils.keras_generator import Generator\n",
    "from utils.losses import weighted_cross_entropy_loss,f1_score_metric\n",
    "from utils.callbacks import get_tensorboard_callback,get_checkpoint_call_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "files=os.listdir(data_dir)\n",
    "array=pd.read_hdf(os.path.join(data_dir,files[0]))\n",
    "P=preprocessor(label_encoder_dir)\n",
    "array=P.process_batch(array)\n",
    "action_col=array.columns=='action'\n",
    "g_config={'labels':6,\n",
    "        'weightage':[1,1,1,1,1,1],\n",
    "        'data_directory':data_dir,\n",
    "        'file_batch_size':1,\n",
    "        'format_':'h5',\n",
    "        'ex_batch_size':10000,\n",
    "        'file_examples':5000,\n",
    "        'max_queue_size':10,\n",
    "        'Preprocessor':P,\n",
    "        'static_weightage':False,\n",
    "         'action_col':action_col}\n",
    "\n",
    "G=Generator(config=g_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_config={'layer_shapes':[200,200,200,200],'Activation':'relu','Output':6,'Input_shape':472, 'model_type':'fc'}\n",
    "my_model=Model(nn_config) \n",
    "f1=f1_score_metric(6)\n",
    "my_model.model.compile(loss=weighted_cross_entropy_loss, optimizer=optimizers.Adam(lr=0.0001),metrics=[\"acc\",f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "p1 = Process(target=G.generate)\n",
    "p1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "my_model.model.fit_generator(generator= G, \n",
    "                    steps_per_epoch  = len(G), \n",
    "                    epochs           = 10, \n",
    "                    verbose          = 1,\n",
    "#                     validation_data  = valid_batch,\n",
    "#                     validation_steps = len(valid_batch),\n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print (G.Data.qsize())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
