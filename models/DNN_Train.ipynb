{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from Preprocessor import preprocessor\n",
    "import keras.layers as L\n",
    "import keras.activations as A\n",
    "import keras.optimizers as O\n",
    "import keras.losses as Loss\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P=preprocessor(r'C:/Users/MuhammadUsman/PycharmProjects/internship.ai')\n",
    "config={'data_directory':r'C:\\Users\\MuhammadUsman\\PycharmProjects\\internship.ai\\Output','file_batch_size':3,'format_':'h5','ex_batch_size':100,'file_examples':1000,'obsnet_col':4,'Preprocessor':P}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import glob\n",
    "class Generator(keras.utils.Sequence):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.DataDirectory = self.config['data_directory']\n",
    "        self.DataFiles = np.array(glob.glob(self.DataDirectory+'/*'+self.config['format_']))\n",
    "        self.Indexes_files = np.array(list(range(len(self.DataFiles))))\n",
    "        self.P=self.config['Preprocessor']\n",
    "        self.Data = []\n",
    "        self.i_e = 0\n",
    "        self.i_f = 0\n",
    "\n",
    "    def fill_buffer(self):\n",
    "        files_batch_size = self.config['file_batch_size']\n",
    "        files=self.DataFiles[self.Indexes_files[self.i_f:self.i_f+files_batch_size]]\n",
    "        self.Data=self.load_files(files, self.config['format_'])\n",
    "        self.i_f += files_batch_size\n",
    "\n",
    "    def load_files(self, files, format_):\n",
    "        data_list = []\n",
    "        if format_ == 'csv':\n",
    "            for i in files:\n",
    "                if i[-4:] == '.csv':\n",
    "                    array = pd.read_csv(os.path.join(self.DataDirectory, i))\n",
    "                    array=P.process_batch(array)\n",
    "                    self.obsnet_col=array.columns=='ob_net'\n",
    "                    self.action_col=array.columns=='action'\n",
    "                    data_list.extend(array.values)\n",
    "        elif format_ == 'h5':\n",
    "            for i in files:\n",
    "                if i[-3:] == '.h5':\n",
    "                    array = pd.read_hdf(os.path.join(self.DataDirectory, i))\n",
    "                    array=P.process_batch(array)\n",
    "                    self.obsnet_col=array.columns=='ob_net'\n",
    "                    self.action_col=array.columns=='action'\n",
    "                    data_list.extend(array.values)\n",
    "        elif format_ == 'npy':\n",
    "            for i in files:\n",
    "                if i[-4:] == '.csv':\n",
    "                    array = np.load(os.path.join(self.DataDirectory, i))\n",
    "                    data_list.extend(array)\n",
    "        return np.array(data_list)\n",
    "    def load_data(self):\n",
    "        self.examples_batch_size = self.config['ex_batch_size']\n",
    "        if self.i_f >= len(self.Indexes_files):\n",
    "            np.random.shuffle(self.Indexes_files)\n",
    "            self.i_f = 0\n",
    "        if self.i_e >= len(self.Data):\n",
    "            self.fill_buffer()\n",
    "            self.indexes_examples = np.arange(0,len(self.Data),dtype= np.int32)\n",
    "            np.random.shuffle(self.indexes_examples)\n",
    "            self.i_e = 0\n",
    "        res=self.Data[self.indexes_examples[self.i_e:self.i_e+self.examples_batch_size]]\n",
    "        self.i_e += self.examples_batch_size\n",
    "        return res\n",
    "    def __len__(self):\n",
    "        return (len(self.DataFiles)*self.config['file_examples'])//self.config['ex_batch_size']\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.load_data()\n",
    "        data1 = data[:,(~self.obsnet_col) & (~self.action_col)]\n",
    "        obsnet = data[:,self.obsnet_col]\n",
    "        action=data[:,self.action_col]\n",
    "        list_obsnet=[]\n",
    "        for i in obsnet:\n",
    "            list_obsnet.append(np.array(i[0]).flatten())\n",
    "        obsnet=np.array(list_obsnet)\n",
    "        return np.c_[data1, obsnet],keras.utils.to_categorical(action,5)\n",
    "G=Generator(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FC_Model():\n",
    "    def __init__(self,config):\n",
    "        self.Neurons=config['Hidden']\n",
    "        self.activation=config['Activation']\n",
    "        self.output=config['Output']\n",
    "        self.input_dim=config['Input_shape']\n",
    "        self.optimizer=config['Optimizer']\n",
    "        self.model=self.make_model()\n",
    "        self.loss()\n",
    "    def make_model(self):\n",
    "        x=L.Input(shape=(self.input_dim,))\n",
    "        inp=x\n",
    "        for i in self.Neurons:\n",
    "            x=L.Dense(i,activation=self.activation)(x)\n",
    "        x=L.Dense(self.output,activation='softmax')(x)\n",
    "        return Model(inp,x)\n",
    "    def loss(self):\n",
    "        self.model.compile(loss=Loss.categorical_crossentropy, optimizer=self.optimizer)\n",
    "    def fit(self,generator):\n",
    "        self.model.fit_generator(generator= generator, \n",
    "                    steps_per_epoch  = len(generator), \n",
    "                    epochs           = 10, \n",
    "                    verbose          = 1,\n",
    "#                     validation_data  = valid_batch,\n",
    "#                     validation_steps = len(valid_batch),\n",
    "                    max_queue_size   = 3)        \n",
    "n_config={'Hidden':[10,10],'Activation':'relu','Output':5,'Optimizer':O.Adam(lr=0.5e-5),'Input_shape':472 }\n",
    "model=FC_Model(n_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 6s 55ms/step - loss: 16.0810 1s - l\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 16.0810\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 16.0810\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 16.0810\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 16.0810\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 16.0810\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 16.0810\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 16.0810\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 16.0810\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 5s 45ms/step - loss: 16.0810\n"
     ]
    }
   ],
   "source": [
    "model.fit(generator=G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
